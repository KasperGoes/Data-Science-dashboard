{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2e77c3-f95a-4b54-b8f9-bc5a07883bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sqlalchemy import create_engine, inspect, Table\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import country_converter as coco\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some pandas display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b6373-9f91-464c-8e66-fd02875674b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading owid data to sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c86fda-d91d-4782-8549-f2c24a08b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a connection to the postgresql database\n",
    "db_conn = create_engine(\"postgresql://student:infomdss@db_dashboard:5432/covid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8ad2c-4208-483f-86a2-17a1bc914a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "owid = pd.read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\", parse_dates=['date'], dayfirst = True, sep=',', skip_blank_lines = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fdc044-41b0-47ec-919e-864c51f0b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input format: csv in which each row is a unique date, country pair and columns contain a lot of covid-related...\n",
    "#...info for the given country on the given date.\n",
    "#Output format: a sql table in which again each row is a unique date, country pair,but only The Netherlands,...\n",
    "#... Italy and Japan, the countries of our interest, are included and only the columns containing information...,\n",
    "#...relevant to our analysis is kept.\n",
    "\n",
    "db_conn.execute(\"DROP TABLE IF EXISTS owid CASCADE;\")\n",
    "owid = owid[(owid.location == 'Italy') | (owid.location=='Japan') | (owid.location == 'Netherlands')]\n",
    "toDrop = ['continent','total_deaths','new_deaths','new_deaths_smoothed','total_deaths_per_million', 'new_deaths_per_million',\n",
    "       'new_deaths_smoothed_per_million','total_tests', 'new_tests',\n",
    "       'total_tests_per_thousand', 'new_tests_per_thousand',\n",
    "       'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n",
    "       'positive_rate', 'tests_per_case', 'tests_units', 'stringency_index',\n",
    "       'population', 'population_density', 'median_age', 'aged_65_older',\n",
    "       'aged_70_older', 'gdp_per_capita', 'extreme_poverty',\n",
    "       'cardiovasc_death_rate', 'diabetes_prevalence', 'female_smokers',\n",
    "       'male_smokers', 'handwashing_facilities','life_expectancy',\n",
    "       'human_development_index', 'excess_mortality_cumulative_absolute',\n",
    "       'excess_mortality_cumulative', 'excess_mortality',\n",
    "       'excess_mortality_cumulative_per_million']\n",
    "toDrop = [x for x in toDrop if x in owid.columns]\n",
    "owid.drop(toDrop, axis = 1, inplace=True)\n",
    "owid.to_sql(\"owid\", db_conn, if_exists='replace')\n",
    "df = pd.read_sql_table('owid', db_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83800588-1b63-4137-90af-e8a67115f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn.execute(\"DROP VIEW IF EXISTS owidWY CASCADE;\")\n",
    "query = '''\n",
    "CREATE OR REPLACE VIEW owidWY AS \n",
    "SELECT *,\n",
    "CAST(EXTRACT(WEEK FROM date) AS int) AS week,\n",
    "CAST(EXTRACT(YEAR FROM date) AS int) AS year\n",
    "FROM owid\n",
    "'''\n",
    "db_conn.execute(query)\n",
    "df = pd.read_sql('SELECT * FROM owidWY',db_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51db97da-022f-4044-849f-bbf2e4755726",
   "metadata": {},
   "source": [
    "# Everything that is per million to per 10.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d81e8c-a876-4142-86ea-24573dedb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We change the per million stat to per 10.000 to increase visability \n",
    "\n",
    "per_million_columns = ['total_cases_per_million','new_cases_per_million', 'new_cases_smoothed_per_million', 'icu_patients_per_million',\n",
    "       'hosp_patients_per_million','weekly_icu_admissions_per_million','weekly_hosp_admissions_per_million', 'new_vaccinations_smoothed_per_million']\n",
    "\n",
    "df[per_million_columns]  = df[per_million_columns].mul(100)\n",
    "\n",
    "#we now also rename the columns\n",
    "df.rename(columns={'total_cases_per_million': 'total_cases_per_tenthousand' ,'new_cases_per_million': 'new_cases_per_tenthousand', \n",
    "                   'new_cases_smoothed_per_million':'new_cases_smoothed_per_tenthousand', 'icu_patients_per_million':'icu_patients_per_tenthousand',\n",
    "                   'hosp_patients_per_million':'hosp_patients_per_tenthousand','weekly_icu_admissions_per_million':'weekly_icu_admissions_per_tenthousand','weekly_hosp_admissions_per_million':'weekly_hosp_admissions_per_tenthousand',\n",
    "                   'new_vaccinations_smoothed_per_million':'new_vaccinations_smoothed_per_tenthousand'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e3188-6b63-4d8e-af8b-9afa5d75a3e8",
   "metadata": {},
   "source": [
    "# Setting vaccination columns before first vaccinations to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43c729-0ce6-40ed-93af-d0b8cf8c5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#because we know for each country when they got their first vaccination we can set all teh vaccinations columns to 0 before that date.\n",
    "#this gives us more data.\n",
    "\n",
    "vaccination_columns = ['total_vaccinations', 'people_vaccinated','people_fully_vaccinated', 'total_boosters', 'new_vaccinations',\n",
    "       'new_vaccinations_smoothed', 'total_vaccinations_per_hundred','people_vaccinated_per_hundred','people_fully_vaccinated_per_hundred',\n",
    "       'total_boosters_per_hundred','new_vaccinations_smoothed_per_million','new_people_vaccinated_smoothed','new_people_vaccinated_smoothed_per_hundred']\n",
    "\n",
    "df.loc[(df['date'] < \"2020-12-27\") & (df['iso_code'] == 'ITA'), vaccination_columns] = 0\n",
    "df.loc[(df['date'] < \"2021-02-17\") & (df['iso_code'] == 'JPN'), vaccination_columns] = 0\n",
    "df.loc[(df['date'] < \"2021-01-18\") & (df['iso_code'] == 'NLD'), vaccination_columns] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bac3c7-30f6-4337-85db-1c0a20a06628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we upload the updated df to sql\n",
    "df = df.iloc[: , 1:]\n",
    "db_conn.execute(\"DROP TABLE IF EXISTS owidtab CASCADE;\")\n",
    "df.to_sql(\"owidtab\", db_conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e79a1-5d52-4664-9f59-61af49252053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('SELECT * FROM owidtab',db_conn,)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79906d33-f428-4daf-8a15-721ce2e4d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(owid['iso_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb59c17-787e-4229-a652-e51f079f67a5",
   "metadata": {},
   "source": [
    "# Loading covariants data to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097175a-53b1-4474-9b5f-a70a1aad1982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input format: json in which first level objects represent countries. Each country has attributes for..\n",
    "#...weekly dates during the pandemic, the total number of analysed covid infection sequences during that week...\n",
    "#...and attributes for number of sequences that were of a given variant during that week.\n",
    "#output format: a sql table where each row is a unique country, date pair and there are columns for...\n",
    "#... country_iso, date total sequences analysed and number of all sequences found. Only data for NLD, ITA...\n",
    "#... and JPN is kept.\n",
    "\n",
    "covarRaw = pd.read_json('https://raw.githubusercontent.com/hodcroftlab/covariants/07b0ea786205ad7269c09d46d2f7b13ef01b667e/cluster_tables/EUClusters_data.json')\n",
    "dfs = []\n",
    "\n",
    "for i in range(len(covarRaw.index)):\n",
    "    country = covarRaw.index[i]\n",
    "    if not country in ['Netherlands','Italy','Japan']:\n",
    "        continue\n",
    "    dtn = covarRaw['countries'][i]\n",
    "    dtn['iso_code'] = coco.convert(country)\n",
    "    df = pd.DataFrame.from_dict(dtn)\n",
    "    df['date'] = pd.to_datetime(df['week'])\n",
    "    df.drop('week',axis=1,inplace=True)\n",
    "    dfs.append(df)\n",
    "    \n",
    "covarRaw = None\n",
    "covar = pd.concat(dfs)\n",
    "covar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86caa56-9d8e-42c9-a1ca-932aba11de85",
   "metadata": {},
   "source": [
    "# Getting percentages instead of total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1becde9e-0b2a-4210-9324-abea94a6fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of knowing the absosulute values for the covariants it is more useful the know the percentage for every variant.\n",
    "#This is done in this codeblock belwo\n",
    "\n",
    "cols = list(covar)\n",
    "#put the date and iso column to the front of the list\n",
    "cols.insert(1, cols.pop(cols.index('date')))\n",
    "cols.insert(2, cols.pop(cols.index('iso_code')))\n",
    "covar = covar.loc[:, cols]\n",
    "\n",
    "#create a column with the unclassified varients\n",
    "covar['other/unknown_variants']= covar['total_sequences'] - covar.iloc[:,3:].sum(axis=1)\n",
    "\n",
    "#instead of absulute valies we calculte \n",
    "columns_to_divide_by = covar.columns.values[3:]\n",
    "covar.iloc[:,3:] = covar[columns_to_divide_by].div(covar.total_sequences, axis=0)\n",
    "\n",
    "covar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eefd19f-4dcf-4b50-bb5c-eee4f437d224",
   "metadata": {},
   "source": [
    "# Adding the fastest growing variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1ad11-69e9-4ca1-8a95-4180ee0db63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see if there is a particular variant that we need to watch out for,\n",
    "#we want to know what variant is the fastest growing one.\n",
    "#this block of code calculates the variant with highest percentage groth over two weeks.\n",
    "\n",
    "def fastest_growing_variant(covar, iso_code):\n",
    "    delta_columns = covar.columns.values[3:-1]\n",
    "\n",
    "    country_df = covar.loc[covar['iso_code'] == iso_code]\n",
    "    \n",
    "    #calculate the difference for each variant\n",
    "    covar_diffs = country_df[delta_columns].diff()\n",
    "    \n",
    "    #add a columns for the variant with the highest change\n",
    "    covar_diffs['highest_change_two_weeks'] = covar_diffs.max(axis=1, numeric_only=True)\n",
    "    covar_diffs['variant_with_highest_delta'] = covar_diffs.idxmax(axis=1)\n",
    "   \n",
    "    country_df = pd.concat([country_df, covar_diffs[['variant_with_highest_delta','highest_change_two_weeks']]], axis=1)\n",
    "    country_df_1 = country_df.fillna(value=np.nan)\n",
    "    return country_df_1\n",
    "\n",
    "ITA, NLD, JPN = fastest_growing_variant(covar, 'ITA'), fastest_growing_variant(covar, 'JPN'), fastest_growing_variant(covar, 'NLD')\n",
    "covar = pd.concat([ITA, JPN, NLD], ignore_index=False)\n",
    "\n",
    "covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc08e1-5655-4a71-b0ce-9f1207a12a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn.execute(\"DROP TABLE IF EXISTS covar CASCADE;\")\n",
    "covar.to_sql(\"covar\", db_conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519213ab-8211-411a-9c4a-0c755de7c9b2",
   "metadata": {},
   "source": [
    "# Loading event cancel data to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123d4c5-5a30-4220-8284-f402378b44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input format: csv in which rows consist of unique countries, columns consist of dates. Each entry... \n",
    "# ...represents the cancelation level for the given date in the given country\n",
    "#output format: a sql table where each row is a unique country date pair, columns for country_iso (from our country selection of NLD,... \n",
    "# ...ITA and JPN), date and event cancellation level\n",
    "\n",
    "eventsRaw = pd.read_csv(\"https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c4m_restrictions_on_gatherings.csv\", sep=',', skip_blank_lines = False)\n",
    "eventsRaw.drop(['Unnamed: 0', 'country_name','region_code','region_name','jurisdiction'],axis=1,inplace=True)\n",
    "\n",
    "dfs= []\n",
    " \n",
    "for iso in ['NLD','JPN','ITA']:\n",
    "    df = eventsRaw[eventsRaw['country_code']==iso]\n",
    "    df.drop('country_code',axis=1,inplace=True)\n",
    "    df= df.T\n",
    "    df.columns = ['event_cancellation_level']\n",
    "    df['date'] = pd.to_datetime(df.index)\n",
    "    df['iso_code'] = iso\n",
    "    dfs.append(df)\n",
    "\n",
    "eventsRaw = None\n",
    "events = pd.concat(dfs)\n",
    "events\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795b058-fdfb-4324-b21c-d874f2c6124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn.execute(\"DROP TABLE IF EXISTS events CASCADE;\")\n",
    "events.to_sql(\"events\", db_conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40dbd7-337b-4e9a-8561-0559baa1280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75168c1-5ded-40be-9b3c-135e9998f961",
   "metadata": {},
   "source": [
    "# Joining all relevant data in single sql view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f23a5-6046-49fc-a473-efa6778a602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining variant data to owid data\n",
    "db_conn.execute(\"DROP VIEW IF EXISTS owidcovar CASCADE;\")\n",
    "query = '''\n",
    "CREATE OR REPLACE VIEW owidcovar AS \n",
    "SELECT \n",
    "    owidtab.*, \"total_sequences\", \"20I (Alpha, V1)\", \"20H (Beta, V2)\", \"20J (Gamma, V3)\", \"21A (Delta)\", \n",
    "    \"21I (Delta)\", \"21J (Delta)\", \"21K (Omicron)\", \"21L (Omicron)\", \"22A (Omicron)\", \"22B (Omicron)\", \"22C (Omicron)\", \n",
    "    \"22D (Omicron)\", \"21B (Kappa)\", \"21D (Eta)\", \"21F (Iota)\", \"21G (Lambda)\", \"21H (Mu)\", \"20B/S:732A\", \"20E (EU1)\", \n",
    "    \"21C (Epsilon)\", \"20A/S:439K\", \"S:677H.Robin1\", \"20A.EU2\", \"20A/S:98F\", \"20B/S:626S\", \"20B/S:1122L\", \"20A/S:126A\", \"20C/S:80Y\", \"other/unknown_variants\",\n",
    "    \"highest_change_two_weeks\",\"variant_with_highest_delta\"\n",
    "FROM owidtab\n",
    "LEFT JOIN covar ON (owidtab.date = covar.date AND owidtab.iso_code = covar.iso_code);\n",
    "'''\n",
    "db_conn.execute(query)\n",
    "df = pd.read_sql('SELECT * FROM owidcovar',db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd1e4f-bd4e-43f8-9c5d-9630b4691968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining event cancellation data to owid and variant data\n",
    "db_conn.execute(\"DROP VIEW IF EXISTS all_relevant CASCADE;\")\n",
    "query = '''\n",
    "CREATE OR REPLACE VIEW all_relevant AS \n",
    "SELECT \n",
    "    owidcovar.*, event_cancellation_level\n",
    "FROM owidcovar\n",
    "LEFT JOIN events ON (owidcovar.date = events.date AND owidcovar.iso_code = events.iso_code);\n",
    "'''\n",
    "db_conn.execute(query)\n",
    "df = pd.read_sql('SELECT * FROM all_relevant',db_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee4ae72-8967-43ec-855a-fdf30bc8193f",
   "metadata": {},
   "source": [
    "# Creating an interpolated df for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6299b7e-51a2-463c-99da-90b6d20c6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the original df and the the columns that you want to be interpolated.\n",
    "#returns a the original df with interpolated columns. This is useful for the data analysis since it gives us more data.\n",
    "def interpolation(df, columns_to_be_interpolated):\n",
    "    \n",
    "    \n",
    "    #we only interpolated between values not before or after, therefor the limit_direction is both\n",
    "    #we want to our interpolate limit to be two weeks\n",
    "    remaining_columns = [elem for elem in df.columns.values.tolist() if elem not in columns_to_be_interpolated]\n",
    "    remaining_columns_df = df[remaining_columns] \n",
    "    df_to_be_interpolated = df[columns_to_be_interpolated]\n",
    "    \n",
    "    dfRes = df_to_be_interpolated.interpolate(method ='linear', limit_direction ='both', limit = 21)\n",
    "    \n",
    "    dfRes = pd.concat([remaining_columns_df, dfRes], axis=1)\n",
    "    \n",
    "    #we also interpolate the values of the highest variant, but we do this with padding\n",
    "    dfRes = dfRes.fillna(value=np.nan)\n",
    "    dfRes['variant_with_highest_delta'].interpolate(method='pad', inplace=True, limit_area='inside')\n",
    "    dfRes['highest_change_two_weeks'].interpolate(method='pad', inplace=True, limit_area='inside')\n",
    "\n",
    "    \n",
    "    return dfRes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fe6ab-9484-48d8-a901-963348f75712",
   "metadata": {},
   "outputs": [],
   "source": [
    "JPN_df = df.loc[df['iso_code'] == 'JPN']\n",
    "ITA_df = df.loc[df['iso_code'] == 'ITA']\n",
    "NLD_df = df.loc[df['iso_code'] == 'NLD']\n",
    "\n",
    "columns_to_be_interpolated_JPN = ['icu_patients', 'icu_patients_per_tenthousand', 'hosp_patients', 'hosp_patients_per_tenthousand', \n",
    "\"total_sequences\", \"20I (Alpha, V1)\", \"20H (Beta, V2)\", \"20J (Gamma, V3)\", \"21A (Delta)\", \n",
    "\"21I (Delta)\", \"21J (Delta)\", \"21K (Omicron)\", \"21L (Omicron)\", \"22A (Omicron)\", \"22B (Omicron)\", \"22C (Omicron)\", \n",
    "\"22D (Omicron)\", \"21B (Kappa)\", \"21D (Eta)\", \"21F (Iota)\", \"21G (Lambda)\", \"21H (Mu)\", \"20B/S:732A\", \"20E (EU1)\", \n",
    "\"21C (Epsilon)\", \"20A/S:439K\", \"S:677H.Robin1\", \"20A.EU2\", \"20A/S:98F\", \"20B/S:626S\", \"20B/S:1122L\", \"20A/S:126A\", \"20C/S:80Y\", \"other/unknown_variants\"]\n",
    "\n",
    "columns_to_be_interpolated_NLD = ['total_vaccinations_per_hundred','people_vaccinated_per_hundred', 'people_fully_vaccinated_per_hundred','total_boosters_per_hundred', \n",
    "           'weekly_icu_admissions', 'weekly_icu_admissions_per_tenthousand', 'weekly_hosp_admissions', 'weekly_hosp_admissions_per_tenthousand',\n",
    "           'total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated','total_boosters']\n",
    "\n",
    "JPN_df_interpolated = interpolation(JPN_df, columns_to_be_interpolated_JPN)\n",
    "ITA_df_interpolated = interpolation(ITA_df, columns_to_be_interpolated_JPN[5:])\n",
    "NLD_df_interpolated = interpolation(NLD_df, columns_to_be_interpolated_NLD + columns_to_be_interpolated_JPN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356e7811-7c35-47c8-bc81-a2ea003896e6",
   "metadata": {},
   "source": [
    "# joining the interpolated data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795a4fe-8313-4ce6-acb3-adf80fa2e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the interpolated datasets per country\n",
    "df_interpolated = pd.concat([ITA_df_interpolated, JPN_df_interpolated, NLD_df_interpolated], ignore_index=False)\n",
    "\n",
    "#merging the interpolated data frame with the old one to create on large dataframes\n",
    "total_df  = pd.merge(df, df_interpolated.add_suffix('_inter'), left_on=['date','iso_code'],right_on = ['date_inter','iso_code_inter'], how='left')\n",
    "total_df  = total_df.fillna(value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08648068-3552-4d2b-90cc-f0819e50e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa5fa4-fa62-43dc-a4ae-7bf771bbb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pushing the interpolated df to SQL\n",
    "db_conn.execute(\"DROP TABLE IF EXISTS total_df CASCADE;\")\n",
    "total_df.to_sql(\"total_df\", db_conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53159354-09e0-43a7-b196-022a756d4537",
   "metadata": {},
   "source": [
    "# Creating views for success factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281bfa66-a9d7-40bc-a0b6-73289b10d85b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#getting the relevant kpi data for cases (excluding variant distribution for now)\n",
    "db_conn.execute(\"DROP VIEW IF EXISTS cases CASCADE;\")\n",
    "query = '''\n",
    "CREATE OR REPLACE VIEW cases AS \n",
    "SELECT iso_code, date,new_cases_per_tenthousand, new_cases_smoothed_per_tenthousand, reproduction_rate\n",
    "FROM all_relevant\n",
    "'''\n",
    "db_conn.execute(query)\n",
    "df = pd.read_sql('SELECT * FROM cases',db_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b702de8-f8c9-4500-a756-b995991a6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the relevant kpi data for cases (including variant distribution)\n",
    "db_conn.execute(\"DROP VIEW IF EXISTS casesplus CASCADE;\")\n",
    "query = '''\n",
    "CREATE OR REPLACE VIEW casesplus AS \n",
    "SELECT iso_code, date,new_cases_per_tenthousand, new_cases_smoothed_per_tenthousand, reproduction_rate,\n",
    "    \"total_sequences\", \"20I (Alpha, V1)\", \"20H (Beta, V2)\", \"20J (Gamma, V3)\", \"21A (Delta)\", \n",
    "    \"21I (Delta)\", \"21J (Delta)\", \"21K (Omicron)\", \"21L (Omicron)\", \"22A (Omicron)\", \"22B (Omicron)\", \"22C (Omicron)\", \n",
    "    \"22D (Omicron)\", \"21B (Kappa)\", \"21D (Eta)\", \"21F (Iota)\", \"21G (Lambda)\", \"21H (Mu)\", \"20B/S:732A\", \"20E (EU1)\", \n",
    "    \"21C (Epsilon)\", \"20A/S:439K\", \"S:677H.Robin1\", \"20A.EU2\", \"20A/S:98F\", \"20B/S:626S\", \"20B/S:1122L\", \"20A/S:126A\", \"20C/S:80Y\"\n",
    "FROM all_relevant\n",
    "'''\n",
    "db_conn.execute(query)\n",
    "df = pd.read_sql('SELECT * FROM casesplus',db_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c47ed-aca8-418b-9f2b-bcc1f4da0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the relevant kpi data for vaccinations\n",
    "query = '''\n",
    "CREATE OR REPLACE VIEW vaccinations AS \n",
    "SELECT iso_code, date, people_fully_vaccinated_per_hundred, total_boosters_per_hundred, new_vaccinations_smoothed_per_tenthousand\n",
    "FROM all_relevant\n",
    "'''\n",
    "db_conn.execute(query)\n",
    "df =pd.read_sql('SELECT * FROM vaccinations',db_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1362cbc-3509-474a-a957-cb0884791bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the relevant kpi data for hospitalizations\n",
    "db_conn.execute(\"DROP VIEW IF EXISTS hospitalizations, weeklyHos CASCADE;\")\n",
    "query = '''\n",
    "CREATE OR REPLACE VIEW hospitalizations AS \n",
    "SELECT all_relevant.iso_code, date, icu_patients_per_tenthousand, weekly_icu_admissions_per_tenthousand, hosp_patients_per_tenthousand\n",
    "FROM all_relevant\n",
    "ORDER BY all_relevant.iso_code ASC, date ASC\n",
    "'''\n",
    "db_conn.execute(query)\n",
    "df = pd.read_sql('SELECT * FROM hospitalizations',db_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b36eff-d47c-49c3-8de2-cfb831a3279f",
   "metadata": {},
   "source": [
    "# Plotting the data simply to increase data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1361b0f-09cb-4c65-bc9c-0b7ac50df662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplePlot(db_conn,isoCode, factor, lastN=-1):\n",
    "    df = pd.read_sql('SELECT * FROM ' + factor,db_conn)\n",
    "    df = df[df.iso_code==isoCode]\n",
    "    if lastN > 0:\n",
    "        df = df.tail(lastN)\n",
    "    kpis = [x for x in df.columns if not x in ['iso_code','date'] ]\n",
    "    for kpi in kpis:\n",
    "        print(kpi)\n",
    "        plt.plot(df.index,kpi,data=df)\n",
    "        plt.title(kpi + ' in ' + isoCode)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c394c-a082-491c-888d-382280d5d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastN = 2000\n",
    "simplePlot(db_conn,'NLD','hospitalizations',lastN)\n",
    "simplePlot(db_conn,'ITA','hospitalizations',lastN)\n",
    "simplePlot(db_conn,'JPN','hospitalizations',lastN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f362d7cd-2702-4d1f-a802-c266e0ecf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastN = 1000\n",
    "simplePlot(db_conn,'NLD','cases',lastN)\n",
    "simplePlot(db_conn,'ITA','cases',lastN)\n",
    "simplePlot(db_conn,'JPN','cases',lastN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e2bcc-da65-4b67-a23b-c5a6cb3b2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastN = 200\n",
    "simplePlot(db_conn,'NLD','vaccinations',lastN)\n",
    "simplePlot(db_conn,'ITA','vaccinations',lastN)\n",
    "simplePlot(db_conn,'JPN','vaccinations',lastN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
